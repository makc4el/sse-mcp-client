{
  "dependencies": [
    "."
  ],
  "graphs": {
    "mcp-sse-agent": {
      "path": "client.py:create_langgraph_agent",
      "description": "MCP SSE Client with LangChain Agent for intelligent conversation processing and tool integration",
      "config_schema": {
        "type": "object",
        "properties": {
          "model_name": {
            "type": "string",
            "description": "The OpenAI model to use",
            "default": "gpt-4o"
          },
          "temperature": {
            "type": "number",
            "description": "Model temperature for creativity",
            "default": 0.7,
            "minimum": 0.0,
            "maximum": 2.0
          },
          "max_tokens": {
            "type": "integer",
            "description": "Maximum tokens per response",
            "default": 4000,
            "minimum": 1,
            "maximum": 8000
          },
          "memory_window": {
            "type": "integer",
            "description": "Number of conversation turns to remember",
            "default": 10,
            "minimum": 1,
            "maximum": 100
          }
        }
      }
    }
  },
  "env": ".env",
  "metadata": {
    "name": "MCP SSE Agent",
    "version": "1.0.0",
    "description": "Advanced MCP client with LangChain agent capabilities",
    "author": "MCP SSE Client Team",
    "tags": ["mcp", "sse", "langchain", "agent", "tools"],
    "repository": "https://github.com/makc4el/sse-mcp-client"
  }
}
